{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"./data/diamonds.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(labels=[\"Unnamed: 0\"],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select_dtypes(include=\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.drop(labels=['price'],axis=1)\n",
    "y=df[\"price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_col=X.select_dtypes(include=\"object\").columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_col=X.select_dtypes(exclude=\"object\").columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_col,numerical_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['clarity'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cut_category=['Ideal', 'Premium', 'Good', 'Very Good', 'Fair']\n",
    "color_category=['E', 'I', 'J', 'H', 'F', 'G', 'D']\n",
    "clarity_category=['SI2', 'SI1', 'VS1', 'VS2', 'VVS2', 'VVS1', 'I1', 'IF']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have to import some sklearn library for pipleline and imputer and standardscaling,Ordinalencoding ,transformer,pipleline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer # for impute the missing values\n",
    "from sklearn.preprocessing import StandardScaler # for scaling purpose\n",
    "from sklearn.preprocessing import OrdinalEncoder # for encode the categorical data\n",
    "\n",
    "# now it for pipleline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we have to create a piple line for that we use the object of pipleline class/library\n",
    "# In a project there will be two pipleline first for numberical data and second for categorical data\n",
    "num_pipeline=Pipeline(\n",
    "\n",
    "        steps=[\n",
    "            (\"imputer\",SimpleImputer()),\n",
    "            (\"scaler\",StandardScaler())\n",
    "        ]\n",
    "\n",
    "\n",
    ")\n",
    "cat_pipleline=Pipeline(\n",
    "    steps=[\n",
    "        (\"imputer\",SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"encoding\",OrdinalEncoder(categories=[cut_category,color_category,clarity_category]))\n",
    "\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_trans=ColumnTransformer(\n",
    "    steps=[\n",
    "        (\"numpipeline\",num_pipeline,numerical_col),\n",
    "        (\"cat_pipleline\",cat_pipleline,categorical_col)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.30,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_trans.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_trans.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_trans.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we have to create the dataframe because when we transform and fit_transform data then it convert into the data into numpy like array,so we have to create the dataframe.\n",
    "X_train=pd.DataFrame(column_trans.fit_transform(X_train),columns=column_trans.get_feature_names_out())\n",
    "X_test=pd.DataFrame(column_trans.transform(X_test),columns=column_trans.get_feature_names_out())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After making the DataFrame in term of fit_transformer and transformer , Now we are able to train our model for that we have to choose a specific machine learning algorithm and on the behalf of algorithm then we check accuracy... and so another things.\n",
    "lets start with importing statements and train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg=LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_predict=reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_scores=r2_score(y_test,Y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae=mean_absolute_error(y_test,Y_predict)\n",
    "mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse=mean_squared_error(y_test,Y_predict,squared=False)\n",
    "mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for perfect and modular coding for linear regression and ridge regression and lasso regression,and elasticnet regression ,,we will write  a code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_check(true_value,predict_value):\n",
    "    mae=mean_absolute_error(true_value,predict_value)\n",
    "    mse=mean_squared_error(true_value,predict_value)\n",
    "    rmse=np.sqrt(mean_squared_error(true_value,predict_value))\n",
    "    r2score=r2_score(true_value,predict_value)*100\n",
    "    return (mae,mse,rmse,r2score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"# for train different different module we have to import first,\n",
    "for train all modules at a time then we have to make a dictionary and gives parameters as name and modules\n",
    "and we have also makes some empty list for further print statements\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression,Ridge,Lasso,ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modules={\n",
    "    \"LinearRegression\":LinearRegression(),\n",
    "    \"Ridge\":Ridge(),\n",
    "    \"Lasso\":Lasso(),\n",
    "    \"ElasticNet\":ElasticNet()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "module_list=[]\n",
    "r2_score_list=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in range(len(list(modules))):\n",
    "    module=list(modules.values())[a]\n",
    "    module.fit(X_train,y_train)\n",
    "    # make prediction along with prediction feature\n",
    "    Y_predict=module.predict(X_test)\n",
    "\n",
    "    # now for check accuracy we have to call accuracy_check method and stored individual in the variables\n",
    "    mae,mse,rmse,r2score=accuracy_check(y_test,Y_predict)\n",
    "\n",
    "    print(list(modules.keys())[a])\n",
    "\n",
    "    module_list.append(module)\n",
    "    print(\"mae is \",mae)\n",
    "    print(\"mse is \",mse)\n",
    "    print(\"rmse is \",rmse)\n",
    "    print(\"r2 score is \",r2score)\n",
    "\n",
    "    r2_score_list.append(r2_score)\n",
    "    print(\"=\"*40)\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "module_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
